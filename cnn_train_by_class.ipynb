{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【说明】\n",
    "### 1、该文档在类编写的CNN模型上，对MNIST数据集进行模型的训练和测试，并在保存的模型的基础上：①实现基于保存的模型对测试集和验证集进行测试；②实现基于保存的模型再次训练\n",
    "### 2、该文档中所使用的CNN模型使用了dropout技术和动态学习率技术，训练好的模型在验证集上最好的准确率是0.9762"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、导入相关函数库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from cnn_inference_by_class import ImageCnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data',one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、首次训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、模型搭建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN模型的前向传播过程、损失函数和精度均已在 ImageCnn() 类中实现，后期只需直接调用即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "cnn = ImageCnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、定义优化函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN模型的优化目标，即损失函数，已经在 ImageCnn() 类中实现，可直接调用即可。故此处只需定义优化函数即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 固定学习率——在刚开始搭建模型时，建议使用固定学习率，后期再进行优化\n",
    "# learning_rate = 0.01 \n",
    "global_step = tf.Variable(0,trainable=False)       # 需从0开始，否则在模型保存时模型的保存名称不准确\n",
    "\n",
    "# 对学习率进行优化——采用指数衰减法调节学习率（在才开始训练时具有较大的学习率，随着训练的进行，学习率逐渐减小）\n",
    "# 指数衰减法的不足：当指数趋于正无穷时，学习率会逐渐趋于0（）\n",
    "learning_rate_basic = 1.5            # 基础学习率\n",
    "decay_rate = 0.9                     # 衰减系数\n",
    "decay_steps = 500                    # 衰减速度（最大迭代次数约为250000）\n",
    "\n",
    "learning_rate = tf.train.exponential_decay(learning_rate=learning_rate_basic,\n",
    "                                          global_step=global_step,\n",
    "                                          decay_steps=decay_steps,\n",
    "                                          decay_rate=decay_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdadeltaOptimizer(learning_rate).minimize(cnn.loss,global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、迭代训练（迭代更新学习参数）、模型保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在训练过程中加入如下操作：\n",
    "#### 1、每显示一次信息就保存一次模型\n",
    "#### 2、每显示一次信息就对测试集进行一次测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 100 epochs, loss on training data is 2.1094846725463867, accuracy on test is 0.7879999876022339\n",
      "After 200 epochs, loss on training data is 1.024778127670288, accuracy on test is 0.8489000201225281\n",
      "After 300 epochs, loss on training data is 0.9430018067359924, accuracy on test is 0.8773000240325928\n",
      "After 400 epochs, loss on training data is 0.63228440284729, accuracy on test is 0.9041000008583069\n",
      "After 500 epochs, loss on training data is 0.6035710573196411, accuracy on test is 0.9204000234603882\n",
      "After 600 epochs, loss on training data is 0.42371881008148193, accuracy on test is 0.9282000064849854\n",
      "After 700 epochs, loss on training data is 0.3792960047721863, accuracy on test is 0.9301999807357788\n",
      "After 800 epochs, loss on training data is 0.30904126167297363, accuracy on test is 0.944100022315979\n",
      "After 900 epochs, loss on training data is 0.19652630388736725, accuracy on test is 0.9491999745368958\n",
      "After 1000 epochs, loss on training data is 0.2855652868747711, accuracy on test is 0.9519000053405762\n",
      "After 1100 epochs, loss on training data is 0.23047448694705963, accuracy on test is 0.95660001039505\n",
      "After 1200 epochs, loss on training data is 0.17124557495117188, accuracy on test is 0.9592999815940857\n",
      "After 1300 epochs, loss on training data is 0.2211221605539322, accuracy on test is 0.9613999724388123\n",
      "After 1400 epochs, loss on training data is 0.18970046937465668, accuracy on test is 0.9635999798774719\n",
      "After 1500 epochs, loss on training data is 0.12328483909368515, accuracy on test is 0.9645000100135803\n",
      "After 1600 epochs, loss on training data is 0.13655559718608856, accuracy on test is 0.9642000198364258\n",
      "After 1700 epochs, loss on training data is 0.18115438520908356, accuracy on test is 0.9638000130653381\n",
      "After 1800 epochs, loss on training data is 0.12543147802352905, accuracy on test is 0.9634000062942505\n",
      "After 1900 epochs, loss on training data is 0.12888231873512268, accuracy on test is 0.9685999751091003\n",
      "After 2000 epochs, loss on training data is 0.09524339437484741, accuracy on test is 0.9700000286102295\n",
      "After 2100 epochs, loss on training data is 0.12364549189805984, accuracy on test is 0.9679999947547913\n",
      "After 2200 epochs, loss on training data is 0.08855859190225601, accuracy on test is 0.9717000126838684\n",
      "After 2300 epochs, loss on training data is 0.13418938219547272, accuracy on test is 0.9682000279426575\n",
      "After 2400 epochs, loss on training data is 0.1062731221318245, accuracy on test is 0.9733999967575073\n",
      "After 2500 epochs, loss on training data is 0.1418100893497467, accuracy on test is 0.9732000231742859\n",
      "After 2600 epochs, loss on training data is 0.05262276530265808, accuracy on test is 0.9753000140190125\n",
      "After 2700 epochs, loss on training data is 0.05948605015873909, accuracy on test is 0.973800003528595\n",
      "After 2800 epochs, loss on training data is 0.12369796633720398, accuracy on test is 0.972599983215332\n",
      "After 2900 epochs, loss on training data is 0.11055455356836319, accuracy on test is 0.9736999869346619\n",
      "After 3000 epochs, loss on training data is 0.09237794578075409, accuracy on test is 0.9763000011444092\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 3000                  # 迭代3000次\n",
    "display_peochs = 100                    # 显示信息的时机（显示的内容需自行定义）\n",
    "batch_size = 500                        # 参与每轮迭代的样本数\n",
    "\n",
    "# 由于存储时，每张图片被转换为 1*784 的矩阵，现在需要将其变为一个 28*28 的矩阵，定义一个函数实现该功能\n",
    "def data_reshape(data):\n",
    "    return np.reshape(data,(-1,28,28,1))        # 不能使用 tf.reshape(), 否则会报错\n",
    "\n",
    "# 保存模型操作\n",
    "saver_1 = tf.train.Saver(max_to_keep=2)\n",
    "saverdir = 'model/cnn_model_by_class/'                   # 模型保存地址\n",
    "\n",
    "# 启动会话窗口，开始训练\n",
    "with tf.Session() as sess_1:\n",
    "    sess_1.run(tf.global_variables_initializer())              # 初始化所有变量\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        train_x,train_y = mnist.train.next_batch(batch_size)\n",
    "        training_feed_dict = {\n",
    "            cnn.input_x: data_reshape(train_x),\n",
    "            cnn.input_y: train_y,\n",
    "            cnn.dropout_keep_prob: 0.8\n",
    "        }\n",
    "        _,training_loss = sess_1.run([optimizer,cnn.loss],training_feed_dict)\n",
    "        \n",
    "        if (epoch+1) % display_peochs == 0:\n",
    "            saver_1.save(sess_1,saverdir+'cnn_model_by_class.ckpt',global_step=global_step)\n",
    "            \n",
    "            test_x, test_y = mnist.test.images,mnist.test.labels                  # 提取测试数据集\n",
    "            test_feed_dict = {\n",
    "                cnn.input_x:data_reshape(test_x),\n",
    "                cnn.input_y:test_y,\n",
    "                cnn.dropout_keep_prob:1.0\n",
    "            }\n",
    "            test_accuracy = sess_1.run(cnn.accuracy,test_feed_dict) # 计算当前训练好的模型的精度\n",
    "            \n",
    "            print(\"After {} epochs, loss on training data is {}, accuracy on test is {}\".format(epoch+1,training_loss,test_accuracy))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、基于保存的模型对测试集再次进行验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于保存的模型进行验证或预测时，模型的结构必须和训练时模型的结构一致。此处，可直接复用 cnn = ImageCnn() 来实现上述要求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/cnn_model_by_class/cnn_model_by_class.ckpt-3300\n",
      "Accuracy on test data is 0.9750999808311462, accuracy on validation data is 0.9761999845504761\n"
     ]
    }
   ],
   "source": [
    "saver_2 = tf.train.Saver(max_to_keep=2)          # 再次创建一个保存的操作\n",
    "saverdir = 'model/cnn_model_by_class/'           # 保存模型的文件目录\n",
    "newest_model = tf.train.latest_checkpoint(saverdir)\n",
    "\n",
    "# 同样需要对数据进行重塑\n",
    "def data_reshape(data):\n",
    "    return np.reshape(data,(-1,28,28,1))        # 不能使用 tf.reshape(), 否则会报错\n",
    "\n",
    "# 重新启动一个会话\n",
    "with tf.Session() as sess_2:\n",
    "    saver_2.restore(sess_2,newest_model)        # 将保存的模型恢复到当前图中\n",
    "    \n",
    "    test_x, test_y = mnist.test.images, mnist.test.labels\n",
    "    test_feed_dict = {\n",
    "                cnn.input_x:data_reshape(test_x),\n",
    "                cnn.input_y:test_y,\n",
    "                cnn.dropout_keep_prob:1.0\n",
    "            }\n",
    "    test_accuracy = sess_2.run(cnn.accuracy,test_feed_dict) # 计算训练好的模型在测试集上的精度\n",
    "    \n",
    "    validation_x, validation_y = mnist.validation.images, mnist.validation.labels\n",
    "    validation_feed_dict = {\n",
    "                cnn.input_x:data_reshape(validation_x),\n",
    "                cnn.input_y:validation_y,\n",
    "                cnn.dropout_keep_prob:1.0\n",
    "            }\n",
    "    validation_accuracy = sess_2.run(cnn.accuracy,validation_feed_dict) # 计算训练好的模型在测试集上的精度\n",
    "            \n",
    "    print(\"Accuracy on test data is {}, accuracy on validation data is {}\".format(test_accuracy,validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 五、基于保存的模型再次进行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于保存的模型进行再次训练时，模型的结构也必须和首次训练的模型结构一致。此处，可直接复用 cnn = ImageCnn() 来实现上述要求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/cnn_model_by_class/cnn_model_by_class.ckpt-3000\n",
      "After 100 epochs, loss on training data is 0.09418675303459167, accuracy on test is 0.9754999876022339\n",
      "After 200 epochs, loss on training data is 0.13629505038261414, accuracy on test is 0.9739000201225281\n",
      "After 300 epochs, loss on training data is 0.06830572336912155, accuracy on test is 0.9750999808311462\n"
     ]
    }
   ],
   "source": [
    "retraining_epochs = 3000                  # 再次训练时的迭代次数\n",
    "retraining_display_peochs = 100           # 再次训练时显示信息的时机\n",
    "retraining_batch_size = 500               # 再次训练时，参加每轮迭代的样本数\n",
    "\n",
    "# 同首次训练时一样，也需要对原始数据进行重塑\n",
    "def data_reshape(data):\n",
    "    return np.reshape(data,(-1,28,28,1))\n",
    "\n",
    "# 创建一个新的 saver 实例，用于恢复之前的模型和保存新训练好的模型\n",
    "saver_3 = tf.train.Saver(max_to_keep=2)\n",
    "saverdir = 'model/cnn_model_by_class/'\n",
    "saved_model = tf.train.latest_checkpoint(saverdir)\n",
    "\n",
    "# 重启一个新的会话窗口\n",
    "with tf.Session() as sess_3:\n",
    "    saver_3.restore(sess_3,saved_model)\n",
    "    \n",
    "    for epoch in range(retraining_epochs):\n",
    "        train_x, train_y = mnist.train.next_batch(retraining_batch_size)\n",
    "        retraining_feed_dict = {\n",
    "            cnn.input_x: data_reshape(train_x),\n",
    "            cnn.input_y: train_y,\n",
    "            cnn.dropout_keep_prob: 0.8\n",
    "        }\n",
    "        _,retraining_loss = sess_3.run([optimizer,cnn.loss],retraining_feed_dict)\n",
    "        \n",
    "        if (epoch+1) % retraining_display_peochs == 0:\n",
    "            test_x, test_y = mnist.test.images,mnist.test.labels                  # 提取测试数据集\n",
    "            test_feed_dict = {\n",
    "                cnn.input_x:data_reshape(test_x),\n",
    "                cnn.input_y:test_y,\n",
    "                cnn.dropout_keep_prob:1.0\n",
    "            }\n",
    "            test_accuracy = sess_3.run(cnn.accuracy,test_feed_dict) # 计算当前训练好的模型的精度\n",
    "\n",
    "            saver_3.save(sess_3,saverdir+'cnn_model_by_class.ckpt',global_step=global_step)\n",
    "            print(\"After {} epochs, loss on training data is {}, accuracy on test is {}\".format(epoch+1,retraining_loss,test_accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
